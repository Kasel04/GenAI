{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "6debae27-a81b-4ad5-ad5c-3f0b26688624",
      "cell_type": "code",
      "source": "# Kasel Carty\n# Assignment 2\n# Professor Forouraghi \n#The purpose of this assignment is to compare the performance of a Multi-Layer Perceptron(MLP) and a Convolutional Neural Network (CNN) in",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "a1c1f00a-4e92-4fdb-b389-99d242bd291d",
      "cell_type": "code",
      "source": "import tensorflow as tf\nfrom tensorflow.keras import layers, models, optimizers, datasets\nimport matplotlib.pyplot as plt\n\n# Load and preprocess the dataset\n(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\nx_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize images\n\n# MLP Model\ndef create_mlp_model(input_shape):\n    model = models.Sequential([\n        layers.Flatten(input_shape=input_shape),\n        layers.Dense(200, activation=\"relu\"),\n        layers.Dropout(0.3),\n        layers.Dense(150, activation=\"relu\"),\n        layers.Dropout(0.3),\n        layers.Dense(10, activation=\"softmax\")\n    ])\n    \n    model.compile(optimizer=optimizers.Adam(learning_rate=0.0005),\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n    \n    return model\n\ninput_shape = (32, 32, 3)  # CIFAR-10 input shape\nmlp_model = create_mlp_model(input_shape)\n\n# Train the MLP model\nmlp_history = mlp_model.fit(x_train, y_train, batch_size=32, epochs=10, validation_split=0.2, shuffle=True)\n\n# CNN Model\ndef create_cnn_model(input_shape):\n    model = models.Sequential()\n    \n    model.add(layers.Conv2D(32, (3, 3), strides=(1, 1), padding='same', input_shape=input_shape))\n    model.add(layers.BatchNormalization())\n    model.add(layers.ReLU())\n    \n    model.add(layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same'))\n    model.add(layers.BatchNormalization())\n    model.add(layers.ReLU())\n    \n    model.add(layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same'))\n    model.add(layers.BatchNormalization())\n    model.add(layers.ReLU())\n    \n    model.add(layers.Flatten())\n    \n    model.add(layers.Dense(128))\n    model.add(layers.ReLU())\n    model.add(layers.Dropout(0.5))\n    \n    model.add(layers.Dense(10, activation='softmax'))\n    \n    model.compile(optimizer=optimizers.Adam(),\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n    \n    return model\n\n# Create the CNN model\ncnn_model = create_cnn_model(input_shape)\n\n# Train the CNN model\ncnn_history = cnn_model.fit(x_train, y_train, batch_size=32, epochs=10, validation_split=0.2)\n\n# Evaluate both models\ntest_loss, test_acc = cnn_model.evaluate(x_test, y_test)\nprint(f\"CNN Test accuracy: {test_acc}\")\n\nmlp_test_loss, mlp_test_acc = mlp_model.evaluate(x_test, y_test)\nprint(f\"MLP Test accuracy: {mlp_test_acc}\")\n\n# Plotting validation accuracy for both models\nplt.figure(figsize=(12, 6))\n\n# CNN validation accuracy\nplt.subplot(1, 2, 1)\nplt.plot(cnn_history.history['val_accuracy'], label='CNN Validation Accuracy', color='blue')\nplt.title('CNN Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.xticks(range(10))\nplt.grid()\nplt.legend()\n\n# MLP validation accuracy\nplt.subplot(1, 2, 2)\nplt.plot(mlp_history.history['val_accuracy'], label='MLP Validation Accuracy', color='orange')\nplt.title('MLP Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.xticks(range(10))\nplt.grid()\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n# Plotting training accuracy for both models\nplt.figure(figsize=(12, 6))\n\n# CNN training accuracy\nplt.subplot(1, 2, 1)\nplt.plot(cnn_history.history['accuracy'], label='CNN Training Accuracy', color='blue')\nplt.title('CNN Training Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.xticks(range(10))\nplt.grid()\nplt.legend()\n\n# MLP training accuracy\nplt.subplot(1, 2, 2)\nplt.plot(mlp_history.history['accuracy'], label='MLP Training Accuracy', color='orange')\nplt.title('MLP Training Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.xticks(range(10))\nplt.grid()\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}